global:
  ownerReferences: []

defaultStorage:
  create: true
  hive:
    databaseName: default
    unmanagedDatabase: true
  isDefault: true
  name: hive
  type: hive

permissions:
  meteringAdmins: []
  meteringViewers: []
  reportExporters: []
  reportingAdmins: []
  reportingViewers: []

monitoring:
  createRBAC: true
  enabled: true
  namespace: openshift-monitoring

openshift-reporting:
  enabled: true
  spec:
    awsBillingReportDataSource:
      enabled: false
    defaultReportDataSources:
      cluster-cpu-capacity-raw:
        spec:
          reportQueryView:
            queryName: cluster-cpu-capacity-raw
      cluster-cpu-usage-raw:
        spec:
          reportQueryView:
            queryName: cluster-cpu-usage-raw
      cluster-memory-capacity-raw:
        spec:
          reportQueryView:
            queryName: cluster-memory-capacity-raw
      cluster-memory-usage-raw:
        spec:
          reportQueryView:
            queryName: cluster-memory-usage-raw
      node-allocatable-cpu-cores:
        spec:
          prometheusMetricsImporter:
            query: |
              kube_node_status_allocatable_cpu_cores * on(node) group_left(provider_id) max(kube_node_info) by (node, provider_id)
      node-allocatable-memory-bytes:
        spec:
          prometheusMetricsImporter:
            query: |
              kube_node_status_allocatable_memory_bytes * on(node) group_left(provider_id) max(kube_node_info) by (node, provider_id)
      node-capacity-cpu-cores:
        spec:
          prometheusMetricsImporter:
            query: |
              kube_node_status_capacity_cpu_cores * on(node) group_left(provider_id) max(kube_node_info) by (node, provider_id)
      node-capacity-memory-bytes:
        spec:
          prometheusMetricsImporter:
            query: |
              kube_node_status_capacity_memory_bytes * on(node) group_left(provider_id) max(kube_node_info) by (node, provider_id)
      node-cpu-allocatable-raw:
        spec:
          reportQueryView:
            queryName: node-cpu-allocatable-raw
      node-cpu-capacity-raw:
        spec:
          reportQueryView:
            queryName: node-cpu-capacity-raw
      node-memory-allocatable-raw:
        spec:
          reportQueryView:
            queryName: node-memory-allocatable-raw
      node-memory-capacity-raw:
        spec:
          reportQueryView:
            queryName: node-memory-capacity-raw
      persistentvolumeclaim-capacity-bytes:
        spec:
          prometheusMetricsImporter:
            query: |
              kubelet_volume_stats_capacity_bytes
      persistentvolumeclaim-capacity-raw:
        spec:
          reportQueryView:
            queryName: persistentvolumeclaim-capacity-raw
      persistentvolumeclaim-phase:
        spec:
          prometheusMetricsImporter:
            query: |
              kube_persistentvolumeclaim_status_phase
      persistentvolumeclaim-phase-raw:
        spec:
          reportQueryView:
            queryName: persistentvolumeclaim-phase-raw
      persistentvolumeclaim-request-bytes:
        spec:
          prometheusMetricsImporter:
            query: |
              max(kube_persistentvolumeclaim_resource_requests_storage_bytes) by (namespace, persistentvolumeclaim) + on (namespace, persistentvolumeclaim) group_left(storageclass, volumename) sum(kube_persistentvolumeclaim_info) by (namespace, persistentvolumeclaim, storageclass, volumename) * 0
      persistentvolumeclaim-request-raw:
        spec:
          reportQueryView:
            queryName: persistentvolumeclaim-request-raw
      persistentvolumeclaim-usage-bytes:
        spec:
          prometheusMetricsImporter:
            query: |
              kubelet_volume_stats_used_bytes
      persistentvolumeclaim-usage-raw:
        spec:
          reportQueryView:
            queryName: persistentvolumeclaim-usage-raw
      persistentvolumeclaim-usage-with-phase-raw:
        spec:
          reportQueryView:
            queryName: persistentvolumeclaim-usage-with-phase-raw
      pod-cpu-request-raw:
        spec:
          reportQueryView:
            queryName: pod-cpu-request-raw
      pod-cpu-usage-raw:
        spec:
          reportQueryView:
            queryName: pod-cpu-usage-raw
      pod-limit-cpu-cores:
        spec:
          prometheusMetricsImporter:
            query: |
              sum(kube_pod_container_resource_limits_cpu_cores) by (pod, namespace, node)
      pod-limit-memory-bytes:
        spec:
          prometheusMetricsImporter:
            query: |
              sum(kube_pod_container_resource_limits_memory_bytes) by (pod, namespace, node)
      pod-memory-request-raw:
        spec:
          reportQueryView:
            queryName: pod-memory-request-raw
      pod-memory-usage-raw:
        spec:
          reportQueryView:
            queryName: pod-memory-usage-raw
      pod-persistentvolumeclaim-request-info:
        spec:
          prometheusMetricsImporter:
            query: |
              kube_pod_spec_volumes_persistentvolumeclaims_info
      pod-request-cpu-cores:
        spec:
          prometheusMetricsImporter:
            query: |
              sum(kube_pod_container_resource_requests_cpu_cores) by (pod, namespace, node)
      pod-request-memory-bytes:
        spec:
          prometheusMetricsImporter:
            query: |
              sum(kube_pod_container_resource_requests_memory_bytes) by (pod, namespace, node)
      pod-usage-cpu-cores:
        spec:
          prometheusMetricsImporter:
            query: |
              label_replace(sum(rate(container_cpu_usage_seconds_total{container_name!="POD",container_name!="",pod_name!=""}[1m])) BY (pod_name, namespace), "pod", "$1", "pod_name", "(.*)") + on (pod, namespace) group_left(node) (sum(kube_pod_info{pod_ip!="",node!="",host_ip!=""}) by (pod, namespace, node) * 0)
      pod-usage-memory-bytes:
        spec:
          prometheusMetricsImporter:
            query: |
              sum(label_replace(container_memory_usage_bytes{container_name!="POD", container_name!="",pod_name!=""}, "pod", "$1", "pod_name", "(.*)")) by (pod, namespace) + on (pod, namespace) group_left(node) (sum(kube_pod_info{pod_ip!="",node!="",host_ip!=""}) by (pod, namespace, node) * 0)

reporting-operator:
  spec:
    affinity: {}
    annotations: {}
    authProxy:
      authenticatedEmailsData: ""
      authenticatedEmailsEnabled: false
      authenticatedEmailsSecretName: reporting-operator-auth-proxy-authenticated-emails
      cookieSecretName: reporting-operator-auth-proxy-cookie-seed
      cookieSeed: ""
      createAuthProxyClusterRole: true
      createAuthenticatedEmailsSecret: true
      createCookieSecret: true
      createHtpasswdSecret: true
      delegateURLsEnabled: false
      delegateURLsPolicy: '{"/": {"group": "metering.openshift.io", "resource": "reports",
        "namespace": "$(NAMESPACE)", "subresource": "export", "verb": "get"}}'
      enabled: false
      htpasswdData: ""
      htpasswdSecretName: reporting-operator-auth-proxy-htpasswd
      image:
        pullPolicy: Always
        repository: openshift/oauth-proxy
        tag: v1.1.0
      resources:
        limits:
          cpu: 50m
          memory: 50Mi
        requests:
          cpu: 50m
          memory: 50Mi
      subjectAccessReviewEnabled: false
      subjectAccessReviewPolicy: '{"group": "metering.openshift.io", "resource": "reports",
        "namespace": "$(NAMESPACE)", "subresource": "export", "verb": "get"}'
    config:
      allNamespaces: false
      awsAccessKeyID: ""
      awsCredentialsSecretName: reporting-operator-aws-credentials-secrets
      awsSecretAccessKey: ""
      createAwsCredentialsSecret: true
      createClusterMonitoringViewRBAC: true
      disablePrometheusMetricsImporter: "false"
      enableFinalizers: "false"
      hiveHost: hive-server:10000
      leaderLeaseDuration: 60s
      logDDLQueries: "false"
      logDMLQueries: "false"
      logLevel: info
      logReports: "false"
      metricsTLS:
        certificateData: null
        createSecret: false
        enabled: true
        privateKeyData: null
        secretName: reporting-operator-metrics-tls-secrets
      prestoHost: presto:8080
      prestoMaxQueryLength: null
      prestoTLS:
        enabled: false
        secretName: ""
      prometheusCertificateAuthority:
        configMap:
          create: false
          enabled: false
          filename: ""
          name: reporting-operator-certificate-authority-config
          value: ""
        useServiceAccountCA: true
      prometheusDatasourceImportFrom: null
      prometheusDatasourceMaxImportBackfillDuration: null
      prometheusDatasourceMaxQueryRangeDuration: null
      prometheusImporter:
        auth:
          tokenSecret:
            create: false
            enabled: false
            name: reporting-operator-prometheus-bearer-secrets
            value: ""
          useServiceAccountToken: true
      prometheusMetricsImporterChunkSize: 5m
      prometheusMetricsImporterPollInterval: 5m
      prometheusMetricsImporterStepSize: 60s
      prometheusURL: https://prometheus-k8s.openshift-monitoring.svc:9091/
      targetNamespaces: []
      tls:
        certificateData: null
        createSecret: false
        enabled: true
        privateKeyData: null
        secretName: reporting-operator-api-tls-secrets
    image:
      pullPolicy: Always
      repository: quay.io/openshift/origin-metering-reporting-operator
      tag: 4.2
    labels: {}
    livenessProbe:
      failureThreshold: 5
      httpGet:
        path: /healthy
        port: 8080
        scheme: HTTP
      initialDelaySeconds: 120
      periodSeconds: 60
      successThreshold: 1
      timeoutSeconds: 60
    metricsService:
      annotations:
        service.alpha.openshift.io/serving-cert-secret-name: reporting-operator-metrics-tls-secrets
    nodeSelector: {}
    readinessProbe:
      failureThreshold: 3
      httpGet:
        path: /ready
        port: 8080
        scheme: HTTP
      initialDelaySeconds: 60
      periodSeconds: 60
      successThreshold: 1
      timeoutSeconds: 60
    replicas: 1
    resources:
      limits:
        cpu: 100m
        memory: 150Mi
      requests:
        cpu: 50m
        memory: 50Mi
    route:
      enabled: false
      name: metering
    service:
      annotations:
        service.alpha.openshift.io/serving-cert-secret-name: reporting-operator-api-tls-secrets
      nodePort: null
      type: ClusterIP
    tolerations: []
    updateStrategy:
      type: RollingUpdate

presto:
  spec:
    config:
      awsAccessKeyID: ""
      awsCredentialsSecretName: presto-aws-credentials
      awsSecretAccessKey: ""
      createAwsCredentialsSecret: true
      sharedVolume:
        createPVC: true
        enabled: false
        mountPath: /user/hive/warehouse
        persistentVolumeClaimName: hive-warehouse-data
        storage:
          persistentVolumeClaimSize: 5Gi
          persistentVolumeClaimStorageClass: null
    hive:
      annotations: {}
      config:
        autoCreateMetastoreSchema: true
        dbConnectionDriver: org.apache.derby.jdbc.EmbeddedDriver
        dbConnectionPassword: null
        dbConnectionURL: jdbc:derby:;databaseName=/var/lib/hive/data;create=true
        dbConnectionUsername: null
        defaultCompression: zlib
        defaultFileFormat: orc
        defaultfs: null
        enableMetastoreSchemaVerification: false
        hdfsConfigMapName: hdfs-config
        metastoreClientSocketTimeout: null
        metastoreURIs: thrift://hive-metastore:9083
        metastoreWarehouseDir: hdfs://hdfs-namenode-proxy:9820/operator_metering/default_hive_warehouse/
        useHdfsConfigMap: true
      image:
        pullPolicy: Always
        repository: quay.io/openshift/origin-metering-hive
        tag: 4.2
      labels: {}
      metastore:
        affinity: {}
        config:
          jvm:
            percentMemoryLimitAsHeap: "50"
          logLevel: info
        livenessProbe:
          failureThreshold: 3
          initialDelaySeconds: 90
          periodSeconds: 30
          successThreshold: 1
          tcpSocket:
            port: 9083
          timeoutSeconds: 15
        nodeSelector: {}
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 20
          successThreshold: 1
          tcpSocket:
            port: 9083
          timeoutSeconds: 15
        resources:
          limits:
            cpu: 500m
            memory: 650Mi
          requests:
            cpu: 500m
            memory: 650Mi
        storage:
          class: null
          create: true
          size: 5Gi
        tolerations: []
      securityContext:
        fsGroup: null
        runAsNonRoot: true
      server:
        affinity: {}
        config:
          jvm:
            percentMemoryLimitAsHeap: "50"
          logLevel: info
        livenessProbe:
          failureThreshold: 3
          initialDelaySeconds: 300
          periodSeconds: 30
          successThreshold: 1
          tcpSocket:
            port: 10000
          timeoutSeconds: 15
        nodeSelector: {}
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 20
          successThreshold: 1
          tcpSocket:
            port: 10000
          timeoutSeconds: 15
        resources:
          limits:
            cpu: 100m
            memory: 500Mi
          requests:
            cpu: 100m
            memory: 500Mi
        tolerations: []
      terminationGracePeriodSeconds: 30
    presto:
      annotations: {}
      config:
        tls:
          enabled: false
          secretName: ""
        connectors:
          extraConnectorFiles: []
        environment: production
        hiveMetastoreURI: thrift://hive-metastore:9083
        maxQueryLength: "10000000"
        metastoreTimeout: null
        nodeSchedulerIncludeCoordinator: true
      coordinator:
        affinity:
          podAntiAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - presto
              topologyKey: kubernetes.io/hostname
        config:
          jvm:
            G1HeapRegionSize: null
            concGCThreads: null
            extraFlags: []
            initiatingHeapOccupancyPercent: null
            maxGcPauseMillis: 200
            parallelGCThreads: null
            percentMemoryLimitAsHeap: "50"
            permSize: null
          logLevel: info
          taskMaxWorkerThreads: null
          taskMinDrivers: null
        nodeSelector: {}
        resources:
          limits:
            cpu: "2"
            memory: 2Gi
          requests:
            cpu: "2"
            memory: 2Gi
        terminationGracePeriodSeconds: 30
        tolerations: []
      image:
        pullPolicy: Always
        repository: quay.io/openshift/origin-metering-presto
        tag: 4.2
      labels: {}
      securityContext:
        fsGroup: null
        runAsNonRoot: true
      worker:
        affinity:
          podAntiAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - presto
              topologyKey: kubernetes.io/hostname
        config:
          jvm:
            G1HeapRegionSize: null
            concGCThreads: null
            extraFlags: []
            initiatingHeapOccupancyPercent: null
            maxGcPauseMillis: null
            parallelGCThreads: null
            percentMemoryLimitAsHeap: "50"
            permSize: null
          logLevel: info
          taskMaxWorkerThreads: null
          taskMinDrivers: null
        nodeSelector: {}
        replicas: 0
        resources:
          limits:
            cpu: "2"
            memory: 2Gi
          requests:
            cpu: "2"
            memory: 2Gi
        terminationGracePeriodSeconds: 30
        tolerations: []

hdfs:
  enabled: true
  spec:
    config:
      datanodeDataDirPerms: "775"
      defaultFS: hdfs://hdfs-namenode-0.hdfs-namenode:9820
      logLevel: info
      namenodeHost: hdfs-namenode-0.hdfs-namenode
      namenodePort: 9820
      replicationFactor: 3
    datanode:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - hdfs-datanode
            topologyKey: kubernetes.io/hostname
      annotations: {}
      labels: {}
      nodeSelector: {}
      replicas: 1
      resources:
        limits:
          cpu: 250m
          memory: 250Mi
        requests:
          cpu: 250m
          memory: 250Mi
      storage:
        class: null
        size: 5Gi
      terminationGracePeriodSeconds: 30
      tolerations: []
    image:
      pullPolicy: Always
      repository: quay.io/openshift/origin-metering-hadoop
      tag: 4.2
    namenode:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - hdfs-namenode
            topologyKey: kubernetes.io/hostname
      annotations: {}
      labels: {}
      nodeSelector: {}
      resources:
        limits:
          cpu: 250m
          memory: 350Mi
        requests:
          cpu: 250m
          memory: 350Mi
      storage:
        class: null
        size: 5Gi
      terminationGracePeriodSeconds: 30
      tolerations: []
    securityContext:
      fsGroup: null
      runAsNonRoot: true
