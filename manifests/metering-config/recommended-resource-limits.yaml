apiVersion: metering.openshift.io/v1
kind: MeteringConfig
metadata:
  name: "operator-metering"
spec:
  reporting-operator:
    spec:
      config:
        prometheus:
          metricsImporter:
            config:
              # reporting-operator does the work of importing Metrics in chunks
              # of 5 minutes (by default), every 5 minutes.
              # This only needs to be adjusted if your cluster is really large,
              # and 5 minutes of data is more than a few hundred metrics per
              # time series.  This comes up when you have hundreds of
              # namespaces and pods.
              chunkSize: "5m"
              pollInterval: "5m"
              # This is the resolution of the metrics. Setting this higher
              # reduces granularity of the data we import, but also reduces the
              # number of metrics returned per query.
              stepSize: "60s"

      # Increasing memory to 500Mi allows reporting-operator to keep more
      # metrics in memory at once and helps when the reporting-operator is
      # backlogged.
      # More CPU is for ensuring it never get's throttled during metrics
      # importing when backlogged.
      resources:
        requests:
          memory: 250Mi
          cpu: 500m
        limits:
          memory: 500Mi
          cpu: 1

  presto:
    spec:
      # for Presto, more memory and more CPUs is better and can speed things
      # up, and becomes necessary when dealing with larger amounts of
      # metrics.
      coordinator:
        resources:
          requests:
            memory: 4Gi
            cpu: 4
          limits:
            memory: 8Gi
            cpu: 8
      worker:
        # Change this from 0 to increase parallelism when generating larger
        # reports.
        # Adjusting replicas doesn't improve ReportDataSource import
        # performance which must go through the coordinator.
        replicas: 0
        resources:
          requests:
            memory: 8Gi
            cpu: 4
          limits:
            memory: 16Gi
            cpu: 8
  hive:
    spec:
      metastore:
        # Hive Metastore often requires more memory, and is heavily utilized
        # by Presto.
        # It tracks a lot of things like table statistics, and is
        # communicated with by both presto, and hive-server.
        #
        # Increasing CPU improves GC performance, as less than a core of CPU
        # is generally not enough for most Java applications.
        resources:
          requests:
            memory: 2Gi
            cpu: 1
          limits:
            memory: 2Gi
            cpu: 4
        storage:
          # class defaults to null, which means using the default storage
          # class.
          # If you have a storageClass which provides SSDs, uncomment and
          # specify it here:
          # class: "fast-ssd"
          class: null
          # Generally the default metastore size of 5Gi is sufficient, but
          # with a large amount of ReportDataSources, you may wish to
          # increase it.
          size: "10Gi"
      server:
        # Hive server is generally mostly idle and currently doesn't require
        # many resources.
        resources:
          requests:
            memory: 500Mi
            cpu: 500m
          limits:
            memory: 1Gi
            cpu: 1
