global:
  ownerReferences: []

unsupportedFeatures:
  enableHDFS: false

storage:
  type: "hive"
  hive: {}

  # Below is an example of what con***REMOVED***guring storage could look like:
  #
  # hive:
  #   type: "hdfs"
  #   hdfs:
  #     namenode: "hdfs-namenode-0.hdfs-namenode:9820"

  # hive:
  #   type: "s3"
  #   s3:
  #     bucket: "bucketname/path/"
  #     secretName: "my-aws-secret"
  #     createBucket: true
  #     region: "us-west-1"

  # hive:
  #   type: "sharedPVC"
  #   sharedPVC:
  #     claimName: "metering-nfs"
  #     createPVC: true
  #     storageClass: null
  #     size: 5Gi
  #     mountPath: "/"

tls:
  enabled: true
  # the name of the secret containing root CA key/cert
  certi***REMOVED***cate: ""
  key: ""
  secretName: "metering-operator-root-ca"

permissions:
  meteringAdmins: []
  meteringViewers: []
  reportExporters: []
  reportingAdmins: []
  reportingViewers: []

monitoring:
  createRBAC: true
  enabled: true
  namespace: openshift-monitoring

openshift-reporting:
  spec:
    defaultStorageLocation:
      enabled: true
      isDefault: true
      name: hive
      type: hive
      hive:
        databaseName: metering
        unmanagedDatabase: false
        location: ""

    awsBillingReportDataSource:
      enabled: false

    defaultReportDataSources:
      enabled: true
      items:
        - name: cluster-cpu-capacity-raw
          spec:
            reportQueryView:
              queryName: cluster-cpu-capacity-raw
        - name: cluster-cpu-usage-raw
          spec:
            reportQueryView:
              queryName: cluster-cpu-usage-raw
        - name: cluster-memory-capacity-raw
          spec:
            reportQueryView:
              queryName: cluster-memory-capacity-raw
        - name: cluster-memory-usage-raw
          spec:
            reportQueryView:
              queryName: cluster-memory-usage-raw
        - name: node-allocatable-cpu-cores
          spec:
            prometheusMetricsImporter:
              query: |
                kube_node_status_allocatable_cpu_cores * on(node) group_left(provider_id) max(kube_node_info) by (node, provider_id)
        - name: node-allocatable-memory-bytes
          spec:
            prometheusMetricsImporter:
              query: |
                kube_node_status_allocatable_memory_bytes * on(node) group_left(provider_id) max(kube_node_info) by (node, provider_id)
        - name: node-capacity-cpu-cores
          spec:
            prometheusMetricsImporter:
              query: |
                kube_node_status_capacity_cpu_cores * on(node) group_left(provider_id) max(kube_node_info) by (node, provider_id)
        - name: node-capacity-memory-bytes
          spec:
            prometheusMetricsImporter:
              query: |
                kube_node_status_capacity_memory_bytes * on(node) group_left(provider_id) max(kube_node_info) by (node, provider_id)
        - name: node-cpu-allocatable-raw
          spec:
            reportQueryView:
              queryName: node-cpu-allocatable-raw
        - name: node-cpu-capacity-raw
          spec:
            reportQueryView:
              queryName: node-cpu-capacity-raw
        - name: node-memory-allocatable-raw
          spec:
            reportQueryView:
              queryName: node-memory-allocatable-raw
        - name: node-memory-capacity-raw
          spec:
            reportQueryView:
              queryName: node-memory-capacity-raw
        - name: persistentvolumeclaim-capacity-bytes
          spec:
            prometheusMetricsImporter:
              query: |
                kubelet_volume_stats_capacity_bytes
        - name: persistentvolumeclaim-capacity-raw
          spec:
            reportQueryView:
              queryName: persistentvolumeclaim-capacity-raw
        - name: persistentvolumeclaim-phase
          spec:
            prometheusMetricsImporter:
              query: |
                kube_persistentvolumeclaim_status_phase
        - name: persistentvolumeclaim-phase-raw
          spec:
            reportQueryView:
              queryName: persistentvolumeclaim-phase-raw
        - name: persistentvolumeclaim-request-bytes
          spec:
            prometheusMetricsImporter:
              query: |
                max(kube_persistentvolumeclaim_resource_requests_storage_bytes) by (namespace, persistentvolumeclaim) + on (namespace, persistentvolumeclaim) group_left(storageclass, volumename) sum(kube_persistentvolumeclaim_info) by (namespace, persistentvolumeclaim, storageclass, volumename) * 0
        - name: persistentvolumeclaim-request-raw
          spec:
            reportQueryView:
              queryName: persistentvolumeclaim-request-raw
        - name: persistentvolumeclaim-usage-bytes
          spec:
            prometheusMetricsImporter:
              query: |
                kubelet_volume_stats_used_bytes
        - name: persistentvolumeclaim-usage-raw
          spec:
            reportQueryView:
              queryName: persistentvolumeclaim-usage-raw
        - name: persistentvolumeclaim-usage-with-phase-raw
          spec:
            reportQueryView:
              queryName: persistentvolumeclaim-usage-with-phase-raw
        - name: pod-cpu-request-raw
          spec:
            reportQueryView:
              queryName: pod-cpu-request-raw
        - name: pod-cpu-usage-raw
          spec:
            reportQueryView:
              queryName: pod-cpu-usage-raw
        - name: pod-limit-cpu-cores
          spec:
            prometheusMetricsImporter:
              query: |
                sum(kube_pod_container_resource_limits_cpu_cores) by (pod, namespace, node)
        - name: pod-limit-memory-bytes
          spec:
            prometheusMetricsImporter:
              query: |
                sum(kube_pod_container_resource_limits_memory_bytes) by (pod, namespace, node)
        - name: pod-memory-request-raw
          spec:
            reportQueryView:
              queryName: pod-memory-request-raw
        - name: pod-memory-usage-raw
          spec:
            reportQueryView:
              queryName: pod-memory-usage-raw
        - name: pod-persistentvolumeclaim-request-info
          spec:
            prometheusMetricsImporter:
              query: |
                kube_pod_spec_volumes_persistentvolumeclaims_info
        - name: pod-request-cpu-cores
          spec:
            prometheusMetricsImporter:
              query: |
                sum(kube_pod_container_resource_requests_cpu_cores) by (pod, namespace, node)
        - name: pod-request-memory-bytes
          spec:
            prometheusMetricsImporter:
              query: |
                sum(kube_pod_container_resource_requests_memory_bytes) by (pod, namespace, node)
        - name: pod-usage-cpu-cores
          spec:
            prometheusMetricsImporter:
              query: |
                label_replace(sum(rate(container_cpu_usage_seconds_total{container_name!="POD",container_name!="",pod_name!=""}[1m])) BY (pod_name, namespace), "pod", "$1", "pod_name", "(.*)") + on (pod, namespace) group_left(node) (sum(kube_pod_info{pod_ip!="",node!="",host_ip!=""}) by (pod, namespace, node) * 0)
        - name: pod-usage-memory-bytes
          spec:
            prometheusMetricsImporter:
              query: |
                sum(label_replace(container_memory_usage_bytes{container_name!="POD", container_name!="",pod_name!=""}, "pod", "$1", "pod_name", "(.*)")) by (pod, namespace) + on (pod, namespace) group_left(node) (sum(kube_pod_info{pod_ip!="",node!="",host_ip!=""}) by (pod, namespace, node) * 0)

reporting-operator:
  spec:
    af***REMOVED***nity: {}
    annotations: {}
    labels: {}
    nodeSelector: {}
    tolerations: []
    replicas: 1

    image:
      pullPolicy: Always
      repository: quay.io/openshift/origin-metering-reporting-operator
      tag: 4.2
      pullSecrets: []

    updateStrategy:
      type: RollingUpdate

    resources:
      limits:
        cpu: 1
        memory: 500Mi
      requests:
        cpu: 500m
        memory: 100Mi

    con***REMOVED***g:
      allNamespaces: false
      enableFinalizers: false
      leaderLeaseDuration: "60s"

      logDDLQueries: false
      logDMLQueries: false
      logReports: false
      logLevel: info

      aws:
        accessKeyID: ""
        secretAccessKey: ""
        createSecret: false
        secretName: ""

      hive:
        host: null
        tls:
          # client cert
          certi***REMOVED***cate: ""
          # client private key
          key: ""
          # CA for the client cert
          caCerti***REMOVED***cate: ""

          createSecret: false
          enabled: false
          secretName: ""
        auth:
          # client cert
          certi***REMOVED***cate: ""
          # client private key
          key: ""

          createSecret: false
          enabled: false
          secretName: ""

      presto:
        host: presto:8080
        maxQueryLength: null

        tls:
          # CA for the server cert
          caCerti***REMOVED***cate: ""

          createSecret: false
          enabled: false
          secretName: ""
        auth:
          # client cert
          certi***REMOVED***cate: ""
          # client private key
          key: ""

          createSecret: false
          enabled: false
          secretName: ""

      prometheus:
        url: https://prometheus-k8s.openshift-monitoring.svc:9091/

        certi***REMOVED***cateAuthority:
          useServiceAccountCA: true
          con***REMOVED***gMap:
            create: false
            enabled: false
            ***REMOVED***lename: ""
            name: reporting-operator-certi***REMOVED***cate-authority-con***REMOVED***g
            value: ""

        metricsImporter:
          enabled: true
          auth:
            useServiceAccountToken: true
            tokenSecret:
              create: false
              enabled: false
              name: reporting-operator-prometheus-bearer-secrets
              value: ""
          con***REMOVED***g:
            chunkSize: 5m
            pollInterval: 5m
            stepSize: 60s
            importFrom: null
            maxImportBack***REMOVED***llDuration: null
            maxQueryRangeDuration: null

      tls:
        api:
          # server cert
          certi***REMOVED***cate: ""
          # server private key
          key: ""
          # CA for the server cert
          caCerti***REMOVED***cate: ""

          createSecret: false
          # default enabled because we expect the cert to be created by the
          # service serving cert controller.
          enabled: true
          secretName: reporting-operator-api-tls-secrets

    rbac:
      createClusterMonitoringViewRBAC: true

    livenessProbe:
      failureThreshold: 5
      initialDelaySeconds: 120
      periodSeconds: 60
      successThreshold: 1
      timeoutSeconds: 60

      httpGet:
        path: /healthy
        port: 8080
        scheme: HTTP

    readinessProbe:
      failureThreshold: 3
      initialDelaySeconds: 60
      periodSeconds: 60
      successThreshold: 1
      timeoutSeconds: 60

      httpGet:
        path: /ready
        port: 8080
        scheme: HTTP

    apiService:
      annotations:
        service.alpha.openshift.io/serving-cert-secret-name: reporting-operator-api-tls-secrets
      nodePort: null
      type: ClusterIP

    route:
      enabled: true
      name: metering

    authProxy:
      enabled: false

      image:
        pullPolicy: Always
        repository: openshift/oauth-proxy
        tag: v1.1.0
        pullSecrets: []

      authenticatedEmails:
        enabled: false
        data: ""
        createSecret: true
        secretName: reporting-operator-auth-proxy-authenticated-emails

      cookie:
        seed: ""
        createSecret: true
        secretName: reporting-operator-auth-proxy-cookie-seed

      delegateURLs:
        enabled: true
        policy: '{"/": {"group": "metering.openshift.io", "resource": "reports", "namespace": "$(NAMESPACE)", "subresource": "export", "verb": "get"}}'

      subjectAccessReview:
        enabled: true
        policy: '{"group": "metering.openshift.io", "resource": "reports", "namespace": "$(NAMESPACE)", "subresource": "export", "verb": "get"}'

      htpasswd:
        data: ""
        createSecret: true
        secretName: reporting-operator-auth-proxy-htpasswd

      rbac:
        createAuthProxyClusterRole: true

      resources:
        limits:
          cpu: 500m
          memory: 100Mi
        requests:
          cpu: 100m
          memory: 50Mi

presto:
  spec:
    labels: {}

    image:
      pullPolicy: Always
      repository: quay.io/openshift/origin-metering-presto
      tag: 4.2

    con***REMOVED***g:
      environment: production
      nodeSchedulerIncludeCoordinator: true
      maxQueryLength: "10000000"

      aws:
        accessKeyID: ""
        secretAccessKey: ""
        createSecret: false
        secretName: ""

      tls:
        # server cert
        certi***REMOVED***cate: ""
        # server private key
        key: ""
        # CA for the server cert
        caCerti***REMOVED***cate: ""

        createSecret: false
        enabled: false
        secretName: ""

      auth:
        # client cert
        certi***REMOVED***cate: ""
        # client private key
        key: ""
        # CA for the client cert
        caCerti***REMOVED***cate: ""

        createSecret: false
        enabled: false
        secretName: ""

      connectors:
        hive:
          hadoopCon***REMOVED***gSecretName: hadoop-con***REMOVED***g
          useHadoopCon***REMOVED***g: true

          metastoreURI: null
          metastoreTimeout: null

          tls:
            # client cert
            certi***REMOVED***cate: ""
            # client private key
            key: ""
            # CA for metastore
            caCerti***REMOVED***cate: ""

            createSecret: false
            enabled: false
            secretName: ""

        extraConnectorFiles: []

    coordinator:
      af***REMOVED***nity:
        podAntiAf***REMOVED***nity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - presto
            topologyKey: kubernetes.io/hostname
      nodeSelector: {}
      tolerations: []
      terminationGracePeriodSeconds: 30

      con***REMOVED***g:
        jvm:
          G1HeapRegionSize: null
          concGCThreads: null
          extraFlags: []
          initiatingHeapOccupancyPercent: null
          maxGcPauseMillis: null
          parallelGCThreads: null
          initialRAMPercentage: "50.0"
          maxRAMPercentage: "50.0"
          minRAMPercentage: null
          permSize: null
          reservedCodeCacheSize: null
          maxCachedBufferSize: null
          maxDirectMemorySize: null
        logLevel: info
        taskMaxWorkerThreads: null
        taskMinDrivers: null
        logLevel: info
        taskMaxWorkerThreads: null
        taskMinDrivers: null

      resources:
        limits:
          cpu: 4
          memory: 4Gi
        requests:
          cpu: 2
          memory: 2Gi

    securityContext:
      fsGroup: null
      runAsNonRoot: true

    worker:
      replicas: 0
      af***REMOVED***nity:
        podAntiAf***REMOVED***nity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - presto
            topologyKey: kubernetes.io/hostname
      nodeSelector: {}
      terminationGracePeriodSeconds: 30
      tolerations: []

      con***REMOVED***g:
        jvm:
          G1HeapRegionSize: null
          concGCThreads: null
          extraFlags: []
          initiatingHeapOccupancyPercent: null
          maxGcPauseMillis: null
          parallelGCThreads: null
          initialRAMPercentage: "50.0"
          maxRAMPercentage: "50.0"
          minRAMPercentage: null
          permSize: null
          reservedCodeCacheSize: null
          maxCachedBufferSize: null
          maxDirectMemorySize: null
        logLevel: info
        taskMaxWorkerThreads: null
        taskMinDrivers: null

      resources:
        limits:
          cpu: 8
          memory: 8Gi
        requests:
          cpu: 4
          memory: 2Gi

hive:
  spec:
    labels: {}
    annotations: {}
    terminationGracePeriodSeconds: 30

    con***REMOVED***g:
      metastoreClientSocketTimeout: null
      metastoreWarehouseDir: null

      defaultCompression: zlib
      defaultFileFormat: orc

      hadoopCon***REMOVED***gSecretName: hadoop-con***REMOVED***g
      useHadoopCon***REMOVED***g: true

      db:
        driver: org.apache.derby.jdbc.EmbeddedDriver
        password: null
        url: jdbc:derby:;databaseName=/var/lib/hive/data;create=true
        username: null

        autoCreateMetastoreSchema: true
        enableMetastoreSchemaVeri***REMOVED***cation: false

      aws:
        accessKeyID: ""
        secretAccessKey: ""
        createSecret: false
        secretName: ""

      sharedVolume:
        enabled: false
        mountPath: /user/hive/warehouse

        createPVC: false
        claimName: hive-warehouse-data
        size: 5Gi
        storageClass: null

    image:
      pullPolicy: Always
      repository: quay.io/openshift/origin-metering-hive
      tag: 4.2
      pullSecrets: []

    metastore:
      af***REMOVED***nity: {}
      nodeSelector: {}
      tolerations: []

      con***REMOVED***g:
        logLevel: info
        jvm:
          initialRAMPercentage: null
          maxRAMPercentage: null
          minRAMPercentage: null

        tls:
          # server cert
          certi***REMOVED***cate: ""
          # server private key
          key: ""
          # CA for the server cert
          caCerti***REMOVED***cate: ""

          enabled: false
          createSecret: false
          secretName: ""

        auth:
          enabled: false

      resources:
        limits:
          cpu: 4
          memory: 2Gi
        requests:
          cpu: 500m
          memory: 650Mi
      storage:
        class: null
        create: true
        size: 5Gi

      livenessProbe:
        failureThreshold: 3
        initialDelaySeconds: 90
        periodSeconds: 30
        successThreshold: 1
        tcpSocket:
          port: 9083
        timeoutSeconds: 15
      readinessProbe:
        failureThreshold: 3
        initialDelaySeconds: 60
        periodSeconds: 20
        successThreshold: 1
        tcpSocket:
          port: 9083
        timeoutSeconds: 15

    server:
      af***REMOVED***nity: {}
      nodeSelector: {}
      tolerations: []

      con***REMOVED***g:
        logLevel: info
        jvm:
          initialRAMPercentage: null
          maxRAMPercentage: null
          minRAMPercentage: null

        tls:
          # server cert
          certi***REMOVED***cate: ""
          # server private key
          key: ""
          # CA for the server cert
          caCerti***REMOVED***cate: ""

          enabled: false
          createSecret: false
          secretName: ""

        auth:
          enabled: false

        metastoreTLS:
          # TLS options for connecting to hive-metastore from hive-server
          # client cert
          certi***REMOVED***cate: ""
          # client private key
          key: ""
          # CA for the client cert
          caCerti***REMOVED***cate: ""

          enabled: false
          createSecret: false
          secretName: ""

      resources:
        limits:
          cpu: 1
          memory: 1Gi
        requests:
          cpu: 500m
          memory: 500Mi

      livenessProbe:
        failureThreshold: 3
        initialDelaySeconds: 300
        periodSeconds: 30
        successThreshold: 1
        tcpSocket:
          port: 10000
        timeoutSeconds: 15
      readinessProbe:
        failureThreshold: 3
        initialDelaySeconds: 60
        periodSeconds: 20
        successThreshold: 1
        tcpSocket:
          port: 10000
        timeoutSeconds: 15

    securityContext:
      fsGroup: null
      runAsNonRoot: true

__ghostunnel:
  image:
    pullPolicy: Always
    repository: quay.io/openshift/origin-ghostunnel
    tag: 4.2

hadoop:
  spec:
    con***REMOVED***gSecretName: hadoop-con***REMOVED***g

    con***REMOVED***g:
      defaultFS: hdfs://hdfs-namenode-0.hdfs-namenode:9820

      aws:
        accessKeyID: ""
        secretAccessKey: ""
        createSecret: false
        secretName: ""

    image:
      pullPolicy: Always
      repository: quay.io/openshift/origin-metering-hadoop
      tag: 4.2
      pullSecrets: null

    hdfs:
      enabled: false
      con***REMOVED***g:
        datanodeDataDirPerms: "775"
        replicationFactor: 3
        logLevel: info

      datanode:
        annotations: {}
        labels: {}
        nodeSelector: {}
        tolerations: []
        terminationGracePeriodSeconds: 30
        replicas: 1

        con***REMOVED***g:
          jvm:
            initialRAMPercentage: null
            maxRAMPercentage: null
            minRAMPercentage: null

        resources:
          limits:
            cpu: 1
            memory: 1Gi
          requests:
            cpu: 250m
            memory: 500Mi

        storage:
          class: null
          size: 5Gi

        af***REMOVED***nity:
          podAntiAf***REMOVED***nity:
            requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - hdfs-datanode
              topologyKey: kubernetes.io/hostname

      namenode:
        annotations: {}
        labels: {}
        nodeSelector: {}
        terminationGracePeriodSeconds: 30
        tolerations: []

        con***REMOVED***g:
          jvm:
            initialRAMPercentage: null
            maxRAMPercentage: null
            minRAMPercentage: null

        resources:
          limits:
            cpu: 2
            memory: 2Gi
          requests:
            cpu: 500m
            memory: 500Mi

        storage:
          class: null
          size: 5Gi

        af***REMOVED***nity:
          podAntiAf***REMOVED***nity:
            requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - hdfs-namenode
              topologyKey: kubernetes.io/hostname

      securityContext:
        fsGroup: null
        runAsNonRoot: true
