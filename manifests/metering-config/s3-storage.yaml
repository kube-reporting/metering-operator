apiVersion: metering.openshift.io/v1alpha1
kind: MeteringCon***REMOVED***g
metadata:
  name: "operator-metering"
spec:
  # If you want to use S3 for storage of reports, and collected metrics, edit
  # the hive metastoreWarehouseDir below, and set awsAccessKeyID and
  # awsSecretAccessKey for reporting-operator and presto

  defaultStorage:
    type: "hive"
    hive:
      # unmanagedDatabase false indicates that this should be created by
      # reporting-operator
      unmanagedDatabase: false
      # feel free to adjust the database name  and location
      databaseName: "metering-s3"
      # s3a:// must be used
      location: "s3a://bucketName/pathInBucket"

  reporting-operator:
    spec:
      con***REMOVED***g:
        # Replace these with your own AWS credentials
        awsAccessKeyID: "REPLACEME"
        awsSecretAccessKey: "REPLACEME"

  presto:
    spec:
      con***REMOVED***g:
        # Replace these with your own AWS credentials
        awsAccessKeyID: "REPLACEME"
        awsSecretAccessKey: "REPLACEME"
      hive:
        con***REMOVED***g:
          # set to false when spec.hdfs.enabled is false
          useHdfsCon***REMOVED***gMap: false
          # Replace this with your bucket
          metastoreWarehouseDir: "s3a://bucketName/pathInBucket"

  hadoop:
    spec:
      hdfs:
        # disable HDFS components when using S3 to avoid wasting resources.
        enabled: false
